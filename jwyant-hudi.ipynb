{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run on master node, NOT IN EMR NOTEBOOK TERMINAL!!!\n",
    "```\n",
    "$ hdfs dfs -copyFromLocal /usr/lib/spark/external/lib/spark-avro.jar /apps/hudi/lib/\n",
    "$ hdfs dfs -copyFromLocal /usr/lib/hudi/hudi-spark-bundle.jar /apps/hudi/lib/\n",
    "```\n",
    "##### Now start running paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.serializer': 'org.apache.spark.serializer.KryoSerializer', 'spark.sql.hive.convertMetastoreParquet': 'false'}, 'jars': ['/apps/hudi/lib/hudi-spark-bundle.jar', '/apps/hudi/lib/spark-avro.jar'], 'kind': 'spark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\": {\n",
    "                \"spark.serializer\":\"org.apache.spark.serializer.KryoSerializer\",\n",
    "                \"spark.sql.hive.convertMetastoreParquet\":\"false\"\n",
    "            },\n",
    "\n",
    "    \"jars\": [\n",
    "            \"/apps/hudi/lib/hudi-spark-bundle.jar\",\n",
    "            \"/apps/hudi/lib/spark-avro.jar\"\n",
    "        ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2a946619484b399e000575796bbe2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>8</td><td>application_1574257904056_0006</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-0-5-233.ec2.internal:20888/proxy/application_1574257904056_0006/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-0-0-239.ec2.internal:8042/node/containerlogs/container_1574257904056_0006_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import org.apache.spark.sql.SaveMode\n",
      "import org.apache.spark.sql.functions._\n",
      "import org.apache.hudi.DataSourceWriteOptions\n",
      "import org.apache.hudi.config.HoodieWriteConfig\n",
      "import org.apache.hudi.hive.MultiPartKeysValueExtractor\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.SaveMode\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.hudi.DataSourceWriteOptions\n",
    "import org.apache.hudi.config.HoodieWriteConfig\n",
    "import org.apache.hudi.hive.MultiPartKeysValueExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a7a652a5524ad6a28cefa75bfdc643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputDataPath: String = s3://athena-examples-us-west-2/elb/parquet/year=2015/month=1/day=1/\n",
      "hudiTableName: String = elb_logs_hudi_cow\n",
      "hudiTablePath: String = s3://jwyant-hudi/elb_logs_hudi_cow\n",
      "hudiOptions: scala.collection.immutable.Map[String,String] = Map(hoodie.datasource.write.precombine.field -> request_timestamp, hoodie.datasource.hive_sync.partition_fields -> request_verb, hoodie.datasource.hive_sync.partition_extractor_class -> org.apache.hudi.hive.MultiPartKeysValueExtractor, hoodie.datasource.hive_sync.table -> elb_logs_hudi_cow, hoodie.datasource.write.operation -> insert, hoodie.datasource.hive_sync.enable -> true, hoodie.datasource.write.recordkey.field -> request_ip, hoodie.table.name -> elb_logs_hudi_cow, hoodie.datasource.hive_sync.assume_date_partitioning -> false, hoodie.datasource.write.partitionpath.field -> request_verb)\n",
      "inputDF: org.apache.spark.sql.DataFrame = [request_timestamp: string, elb_name: string ... 17 more fields]\n"
     ]
    }
   ],
   "source": [
    "val inputDataPath = \"s3://athena-examples-us-west-2/elb/parquet/year=2015/month=1/day=1/\"\n",
    "val hudiTableName = \"elb_logs_hudi_cow\"\n",
    "val hudiTablePath = \"s3://jwyant-hudi/\" + hudiTableName\n",
    "\n",
    "// Set up our Hudi Data Source Options\n",
    "val hudiOptions = Map[String,String](\n",
    "    DataSourceWriteOptions.RECORDKEY_FIELD_OPT_KEY -> \"request_ip\",\n",
    "    DataSourceWriteOptions.PARTITIONPATH_FIELD_OPT_KEY -> \"request_verb\", \n",
    "    HoodieWriteConfig.TABLE_NAME -> hudiTableName, \n",
    "    DataSourceWriteOptions.OPERATION_OPT_KEY ->\n",
    "        DataSourceWriteOptions.INSERT_OPERATION_OPT_VAL, \n",
    "    DataSourceWriteOptions.PRECOMBINE_FIELD_OPT_KEY -> \"request_timestamp\", \n",
    "    DataSourceWriteOptions.HIVE_SYNC_ENABLED_OPT_KEY -> \"true\", \n",
    "    DataSourceWriteOptions.HIVE_TABLE_OPT_KEY -> hudiTableName, \n",
    "    DataSourceWriteOptions.HIVE_PARTITION_FIELDS_OPT_KEY -> \"request_verb\", \n",
    "    DataSourceWriteOptions.HIVE_ASSUME_DATE_PARTITION_OPT_KEY -> \"false\", \n",
    "    DataSourceWriteOptions.HIVE_PARTITION_EXTRACTOR_CLASS_OPT_KEY ->\n",
    "        classOf[MultiPartKeysValueExtractor].getName)\n",
    "\n",
    "// Read data from S3 and create a DataFrame with Partition and Record Key\n",
    "val inputDF = spark.read.format(\"parquet\").load(inputDataPath)\n",
    "\n",
    "// Write data into the Hudi dataset\n",
    "inputDF.write.\n",
    "    format(\"org.apache.hudi\").\n",
    "    options(hudiOptions).\n",
    "    mode(SaveMode.Overwrite).\n",
    "    save(hudiTablePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7cb4e95212402ca0375a0fec8ce59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res23: Long = 10491958\n"
     ]
    }
   ],
   "source": [
    "// Count the records (should be 10491958)\n",
    "inputDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run in Hive\n",
    "```\n",
    "hive> use default;\n",
    "hive> select count(*) from elb_logs_hudi_cow;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2667876b99c24f919e4de8ff2bd034a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requestIpToUpdate: String = 243.80.62.181\n",
      "sqlStatement: String = SELECT elb_name FROM elb_logs_hudi_cow WHERE request_ip = '243.80.62.181'\n"
     ]
    }
   ],
   "source": [
    "val requestIpToUpdate = \"243.80.62.181\"\n",
    "val sqlStatement = s\"SELECT elb_name FROM elb_logs_hudi_cow WHERE request_ip = '$requestIpToUpdate'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe940bdfbc046df97f17cb007fd3032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|    elb_name|\n",
      "+------------+\n",
      "|elb_demo_003|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(sqlStatement).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5ac28465bf46eab2c3dbf83bb696f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updateDF: org.apache.spark.sql.DataFrame = [request_timestamp: string, elb_name: string ... 17 more fields]\n"
     ]
    }
   ],
   "source": [
    "// Create a DataFrame with a single record and update column value\n",
    "val updateDF = inputDF.filter(col(\"request_ip\") === requestIpToUpdate).withColumn(\"elb_name\", lit(\"elb_demo_001\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ecfc247446f448dac41125972b86920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Write the DataFrame as an update to existing Hudi dataset\n",
    "updateDF.write.\n",
    "    format(\"org.apache.hudi\").\n",
    "    options(hudiOptions).\n",
    "    option(DataSourceWriteOptions.OPERATION_OPT_KEY, DataSourceWriteOptions.UPSERT_OPERATION_OPT_VAL).\n",
    "    mode(SaveMode.Append).\n",
    "    save(hudiTablePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace219d79f9c469d93b11b2774f8d4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|    elb_name|\n",
      "+------------+\n",
      "|elb_demo_001|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(sqlStatement).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f250d3af744aed88266442649b0d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Write the DataFrame with an EmptyHoodieRecordPayload for deleting a record\n",
    "updateDF.write.format(\"org.apache.hudi\").\n",
    "    options(hudiOptions).\n",
    "    option(DataSourceWriteOptions.OPERATION_OPT_KEY, DataSourceWriteOptions.UPSERT_OPERATION_OPT_VAL).\n",
    "    option(DataSourceWriteOptions.PAYLOAD_CLASS_OPT_KEY, \"org.apache.hudi.EmptyHoodieRecordPayload\").\n",
    "    mode(SaveMode.Append).\n",
    "    save(hudiTablePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be5177f3e7a498482a8e2bcf2c44921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|elb_name|\n",
      "+--------+\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(sqlStatement).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Run in bash\n",
    "$ /usr/lib/hudi/cli/bin/hudi-cli.sh\n",
    "// Now in hudi-cli\n",
    "hudi->connect --path s3://jwyant-hudi/elb_logs_hudi_cow/\n",
    "hudi:elb_logs_hudi_cow->commits show\n",
    "hudi:elb_logs_hudi_cow->commit rollback --commit {last commit here}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa09a8d2fce43a48f97eee21045d904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|    elb_name|\n",
      "+------------+\n",
      "|elb_demo_001|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(sqlStatement).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
